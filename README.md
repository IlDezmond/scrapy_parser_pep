# scrapy_parser_pep

## Описание
Асинхронный парсер для сайта python.org
Парсер выводит собранную информацию в два файла .csv:
1. первый файл — список всех PEP: номер, название и статус.
2. второй файл — сводку по статусам PEP, сколько найдено документов в каждом статусе (статус, количество).

### Использованные технологии
- Python
- Scrapy

### Как запустить проект:

Клонировать репозиторий и перейти в него в командной строке:

```
git clone git@github.com:IlDezmond/scrapy_parser_pep.git
```

```
cd scrapy_parser_pep
```

Создать и активировать виртуальное окружение:

```
python3 -m venv env
```

```
source env/bin/activate
```

Установить зависимости из файла requirements.txt:

```
pip install -r requirements.txt
```
Запуск парсерса
```
scrapy crawl pep
```
Данные сохраняются в файлах.csv в директории results, находящейся в корне проекта

